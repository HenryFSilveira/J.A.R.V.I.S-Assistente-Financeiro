# main.py 
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel, Field
from dotenv import load_dotenv
from google import genai
from google.genai import types
from google.genai.client import Chat 
import os
from typing import Dict, Optional

# Carrega vari√°veis de ambiente 
load_dotenv() 

GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")

# Instru√ß√£o de sistema que define o papel do modelo Gemini
SYSTEM_INSTRUCTION = (
    "Voc√™ √© um assistente especializado em finan√ßas e investimentos, "
    "focado em fornecer an√°lises, dicas de or√ßamento e explica√ß√µes sobre termos e "
    "estrat√©gias financeiras. Mantenha um tom profissional e informativo."
)

client: Optional[genai.Client] = None
# Dicion√°rio global para armazenar as sess√µes de chat. 
# A chave √© o user_id e o valor √© a inst√¢ncia Chat, mantendo o contexto conversacional.
CHAT_SESSIONS: Dict[str, Chat] = {} # <--- CORRIGIDO: Usa a classe Chat importada

if GEMINI_API_KEY:
    try:
        # Inicializa o cliente Gemini com a chave de API
        client = genai.Client(api_key=GEMINI_API_KEY)
        print("Cliente Gemini inicializado com sucesso!")
    except Exception as e:
        print(f"ERRO: N√£o foi poss√≠vel inicializar o cliente Gemini. Detalhe: {e}")
        client = None
else:
    print("AVISO: Chave GEMINI_API_KEY n√£o encontrada. O servi√ßo de IA estar√° indispon√≠vel.")


# Modelo Pydantic para a requisi√ß√£o de chat (valida√ß√£o de entrada)
class ChatRequest(BaseModel):
    # user_id para identificar o usu√°rio e recuperar seu contexto
    user_id: str = Field(..., example="Pablo")
    message: str = Field(..., example="Qual a diferen√ßa entre LCI e LCA?")
    
# Modelo Pydantic para a resposta de chat (estrutura√ß√£o da sa√≠da)
class ChatResponse(BaseModel):
    response: str = Field(..., example="LCI e LCA s√£o t√≠tulos de renda fixa isentos de Imposto de Renda, lastreados, respectivamente, nos setores imobili√°rio e do agroneg√≥cio.")
    source_model: str = "Gemini-2.5-Flash (Especialista Financeiro)"

app = FastAPI(
    title="üí∞ J.A.R.V.I.S - Assistente financeiro",
    description="API para um assistente que ajuda com conceitos financeiros, integrada ao Google Gemini e com contexto por usu√°rio.",
    version="1.0.0",
)

# Rota de sa√∫de simples, gera a documenta√ß√£o do Swagger em /docs
@app.get("/")
def read_root():
    return {"status": "ok", "message": "Assistente LLM pronto. Acesse /docs para a documenta√ß√£o interativa."}

# Rota principal para processar mensagens do chat
@app.post("/chat", response_model=ChatResponse)
async def process_chat(request: ChatRequest):
    # Verifica a disponibilidade do cliente de IA (tratamento de erro 503)
    if not client:
        raise HTTPException(
            status_code=503,
            detail="Servi√ßo de IA indispon√≠vel. Verifique sua chave de API ou conex√£o.",
        )

    user_id = request.user_id
    
    # L√≥gica para gerenciar o contexto conversacional por usu√°rio
    if user_id not in CHAT_SESSIONS:
        try:
            # Cria uma nova sess√£o de chat (com hist√≥rico vazio) e aplica a SYSTEM_INSTRUCTION
            chat_session = client.chats.create(
                model="gemini-2.5-flash",
                config=types.GenerateContentConfig(
                    system_instruction=SYSTEM_INSTRUCTION
                )
            )
            CHAT_SESSIONS[user_id] = chat_session
            print(f"Nova sess√£o de chat criada para o usu√°rio: {user_id}")
        except Exception as e:
            print(f"Erro ao criar nova sess√£o de chat: {e}")
            # Erro interno na cria√ß√£o da sess√£o (tratamento de erro 500)
            raise HTTPException(
                status_code=500,
                detail="Erro interno ao iniciar a sess√£o de IA.",
            )
    else:
        # Recupera a sess√£o existente para continuar a conversa (manter o contexto)
        chat_session = CHAT_SESSIONS[user_id]

    try:
        # Envia a mensagem do usu√°rio para a sess√£o de chat, que inclui o hist√≥rico anterior
        response = chat_session.send_message(request.message)

        # Retorna a resposta estruturada em JSON
        return ChatResponse(
            response=response.text,
            source_model="Gemini-2.5-Flash (Especialista Financeiro)"
        )

    except Exception as e:
        print(f"Erro na comunica√ß√£o com a API Gemini: {e}")
        # Erro interno durante a comunica√ß√£o com a API (tratamento de erro 500)
        raise HTTPException(
            status_code=500,
            detail="Erro interno ao processar a requisi√ß√£o com o modelo de IA.",
        )

if __name__ == "__main__":
    # Inicializa o servidor Uvicorn para rodar o FastAPI
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
